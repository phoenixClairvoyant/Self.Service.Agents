{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /usr/local/lib/python3.11/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "/var/folders/q_/1rtycvc12yn656cyx9nxsl_m0000gn/T/ipykernel_42683/1323392096.py:26: DeprecationWarning: The `trulens_eval` module is deprecated. See https://trulens.org/docs/trulens/guides/trulens_eval_migration for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval import FeedbackMode, Select, Tru\n",
      "/var/folders/q_/1rtycvc12yn656cyx9nxsl_m0000gn/T/ipykernel_42683/1323392096.py:27: DeprecationWarning: The `trulens_eval.feedback` module is deprecated. See https://trulens.org/docs/trulens/guides/trulens_eval_migration for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval.feedback import Feedback\n",
      "/var/folders/q_/1rtycvc12yn656cyx9nxsl_m0000gn/T/ipykernel_42683/1323392096.py:30: DeprecationWarning: Class `TruSession` has moved:\n",
      "\tNew import: `from trulens.core.session import TruSession`\n",
      " See https://trulens.org/docs/trulens/guides/trulens_eval_migration for instructions on migrating to `trulens` modules.\n",
      "  tru = Tru()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ TruSession initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser, SentenceWindowNodeParser, get_leaf_nodes\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "from llama_index.core.indices.postprocessor import SentenceTransformerRerank, MetadataReplacementPostProcessor\n",
    "from llama_index.core.query_engine import RouterQueryEngine, RetrieverQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector, LLMMultiSelector\n",
    "from llama_index.core import (SummaryIndex, Document,\n",
    "                              VectorStoreIndex, StorageContext,\n",
    "                              ServiceContext, load_index_from_storage,\n",
    "                              SimpleDirectoryReader, VectorStoreIndex, Settings)\n",
    "\n",
    "from llama_index.core.selectors import (\n",
    "    PydanticMultiSelector,\n",
    "    PydanticSingleSelector,\n",
    ")\n",
    "\n",
    "from trulens.core import TruSession\n",
    "from trulens.apps.llamaindex.tru_llama import TruLlama\n",
    "from trulens_eval import FeedbackMode, Select, Tru\n",
    "from trulens_eval.feedback import Feedback\n",
    "from trulens.providers.openai.provider import OpenAI as fOpenAI\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['GEMINI_API_KEY'] = os.getenv('GEMINI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder=\"./llamaindex/datastore/platform_wikis/docs/architectural_decision_records\"\n",
    "#data_files = [\"architectural_decision_records/\"]\n",
    "use_gemini = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Gemini() if use_gemini else OpenAI()\n",
    "\n",
    "Settings.llm = llm\n",
    "documents = SimpleDirectoryReader(input_dir=data_folder).load_data()\n",
    "\n",
    "        \n",
    "# Old implementtion\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "vanilla_query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "        \n",
    "# New implementation\n",
    "# initialize storage context (by default it's in-memory)\n",
    "nodes_00 = Settings.node_parser.get_nodes_from_documents(documents)\n",
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes_00)\n",
    "summary_index = SummaryIndex(nodes_00, storage_context=storage_context)\n",
    "vector_index = VectorStoreIndex(nodes_00, storage_context=storage_context)\n",
    "\n",
    "list_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\", use_async=True)\n",
    "vector_query_engine = vector_index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input args will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input kwargs will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/1rtycvc12yn656cyx9nxsl_m0000gn/T/ipykernel_42683/2824834168.py:5: DeprecationWarning: Class `Feedback` has moved:\n",
      "\tOld import: `from trulens_eval.feedback import Feedback`\n",
      "\tNew import: `from trulens.feedback import Feedback`\n",
      " See https://trulens.org/docs/trulens/guides/trulens_eval_migration for instructions on migrating to `trulens` modules.\n",
      "  f_qa_relevance = Feedback(\n"
     ]
    }
   ],
   "source": [
    "# Feedback\n",
    "provider = fOpenAI()\n",
    "context_selection = TruLlama.select_source_nodes().node.text\n",
    "\n",
    "f_qa_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons,\n",
    "    name=\"Answer Relevance\"\n",
    "    ).on_input_output()\n",
    "\n",
    "f_qs_relevance = (\n",
    "    Feedback(provider.qs_relevance_with_cot_reasons,\n",
    "    name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    "    .aggregate(np.mean))\n",
    "\n",
    "f_groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons,\n",
    "             name = \"Groundedness\")\n",
    "            .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "            .on_output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "\"What is the purpose of using Architectural Decision Records in this project?\",\n",
    "\"What format are the ADRs stored in?\",\n",
    "\"What are the required fields in the YAML front matter of an ADR?\",\n",
    "\"What is the format for the 'id' field in an ADR?\",\n",
    "\"What are the possible values for the 'status' field in an ADR?\",\n",
    "\"When is the 'deprecated by' field used in an ADR?\",\n",
    "\"What main sections should be included in the body of an ADR?\",\n",
    "\"How should the filename of an ADR be structured?\",\n",
    "\"Where are the ADRs stored in the project directory structure?\",\n",
    "\"What cloud-related decision is made in ADR-002?\",\n",
    "\"What is the preferred approach for building solutions according to ADR-002?\",\n",
    "\"What architectural approach is adopted in ADR-003?\",\n",
    "\"Who proposed the Data Mesh Architecture and when?\",\n",
    "\"What are the levels (L0-L3) referred to in ADR-003?\",\n",
    "\"What decision is made regarding cloud services in ADR-004?\",\n",
    "\"What linting tools are adopted according to ADR-005?\",\n",
    "\"What is the structure of the CI pipeline as described in ADR-006?\",\n",
    "\"What is the purpose of using changelogs as mentioned in ADR-007?\",\n",
    "\"What types of changes should be documented in a changelog?\",\n",
    "\"What is the preferred approach for cloud solutions as per ADR-008?\",\n",
    "\"Which data storage solution is chosen as the first supported primary data storage substrate in ADR-009?\",\n",
    "\"What tool is chosen for Infrastructure as Code (IaC) in ADR-010?\",\n",
    "\"What AI and ML compute engine is chosen as the first supported option in ADR-011?\",\n",
    "\"What container technology is adopted according to ADR-012?\",\n",
    "\"What tool is chosen for developing REST APIs in ADR-013?\",\n",
    "\"What change is made regarding Docker in ADR-014?\",\n",
    "\"What is the multi-part naming standard proposed in ADR-015?\",\n",
    "\"How many parts are in the proposed resource naming standard?\",\n",
    "\"What is the preferred separator for resource names according to ADR-015?\",\n",
    "\"What decision is made regarding Databricks in ADR-016?\",\n",
    "\"What tagging strategy is adopted for Docker images in ADR-017?\",\n",
    "\"What decision is made regarding Azure Monitor in ADR-018?\",\n",
    "\"What tool is chosen for managing Terraform state and secrets in ADR-019?\",\n",
    "\"What are the guidelines for developing Terraform modules as per ADR-020?\",\n",
    "\"What is the purpose of the resource tagging convention described in ADR-021?\",\n",
    "\"How many required tags are specified in ADR-021?\",\n",
    "\"What decision is made regarding cloud resource RBAC strategy in ADR-029?\",\n",
    "\"What network architecture is adopted in ADR-028?\",\n",
    "\"What is the purpose of using Unity Catalog as described in ADR-027?\",\n",
    "\"What vulnerability scanning tool is implemented in the pipelines according to ADR-024?\",\n",
    "\"What is the purpose of using OpenTelemetry as described in ADR-040?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-merging\n",
    "\n",
    "def build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\",\n",
    "    chunk_sizes=None,\n",
    "):\n",
    "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
    "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "    merging_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "    )\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        automerging_index = VectorStoreIndex(\n",
    "            leaf_nodes, storage_context=storage_context, service_context=merging_context\n",
    "        )\n",
    "        automerging_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        automerging_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=merging_context,\n",
    "        )\n",
    "    return automerging_index\n",
    "\n",
    "\n",
    "def get_automerging_query_engine(\n",
    "    automerging_index,\n",
    "    similarity_top_k=12,\n",
    "    rerank_top_n=6,\n",
    "):\n",
    "    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n",
    "    retriever = AutoMergingRetriever(\n",
    "        base_retriever, automerging_index.storage_context, verbose=True\n",
    "    )\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "    auto_merging_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever, node_postprocessors=[rerank]\n",
    "    )\n",
    "    return auto_merging_engine\n",
    "\n",
    "auto_merging_index = build_automerging_index(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    embed_model=\"BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\",\n",
    "    chunk_sizes=[2048,512],\n",
    ")\n",
    "\n",
    "auto_merging_engine = get_automerging_query_engine(\n",
    "    auto_merging_index,\n",
    "    similarity_top_k=12,\n",
    "    rerank_top_n=6,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/1rtycvc12yn656cyx9nxsl_m0000gn/T/ipykernel_42683/3125012484.py:16: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "# Sentence Window\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index\",\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            documents, service_context=sentence_context\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "\n",
    "def get_sentence_window_query_engine(\n",
    "    sentence_index, similarity_top_k=6, rerank_top_n=2\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    embed_model=\"BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index\",\n",
    ")\n",
    "sentence_window_engine = get_sentence_window_query_engine(\n",
    "    sentence_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_query_engine(question_list, query_engine, app_name):\n",
    "    tru_recorder = TruLlama(\n",
    "        query_engine,\n",
    "        app_id=app_name,\n",
    "        feedbacks=[\n",
    "            f_qa_relevance,\n",
    "            f_qs_relevance,\n",
    "            f_groundedness\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for question in question_list:\n",
    "        with tru_recorder as recording:\n",
    "            query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_query_engine(eval_questions, vanilla_query_engine, \"Vanilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_query_engine(eval_questions, vector_query_engine, \"Vector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_query_engine(eval_questions, list_query_engine, \"Summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_query_engine(eval_questions, sentence_window_engine, \"Sentence Window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_query_engine(eval_questions, auto_merging_engine, \"Auto-merging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
