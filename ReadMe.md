The project is a research into the use of Llamaindex & crewAI for the development of an LLM agent application. The goal is to create a scalable and automated way to improve the agent's performance and reasoning capabilities.


## Failure modes
    - what does good look like?
    - what does bad look like?
## Good prompts (could we need a prompt refinement step?)


## End output: Use cases

- Generating a IAC for a new Azure Resource
- ADRs'
  - Help me generate an ADR using existing context
  - Check my current work aganist ADRs for compliance.
    - Check code against ADRs
    - Check designs/diagrams against ADRs
  - Given the work I want to do which ADRs are relevant for me to consider? Could we improve it?
  
- Playbooks
- What is required for me to be compliant with a playbook given this process?
- Generate scaffolding given a playbook process.
- Generate a new playbook given a set of playbook standards.
